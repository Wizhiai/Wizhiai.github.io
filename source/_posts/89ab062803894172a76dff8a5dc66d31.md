---
layout: post
title: (6 封私信 / 77 条消息) mysql 优化方法有哪些？ - 知乎
abbrlink: 89ab062803894172a76dff8a5dc66d31
tags: []
categories:
  - 技术
  - 技术文档
date: 1706518352607
updated: 1706518352607
---

<a id="ariaTipText"></a><img width="1" height="1" src=":/15e6ca43ad054afcae086b06ee874491"/>

[](https://www.zhihu.com)

- [首页](https://www.zhihu.com/)
- [知乎知学堂](https://www.zhihu.com/education/learning)
- [发现](https://www.zhihu.com/explore)
- [等你来答](https://www.zhihu.com/question/waiting)

[](https://www.zhihu.com/creator)

# mysql 优化方法有哪些？

链接复制成功！

[数据库](https://www.zhihu.com/topic/19552067)

[面试](https://www.zhihu.com/topic/19552079)

[MySQL](https://www.zhihu.com/topic/19554128)

[MySQL 入门](https://www.zhihu.com/topic/19667043)

[MySQL DBA](https://www.zhihu.com/topic/20075899)

# mysql 优化方法有哪些？

被浏览

**138,053**

[查看全部 42 个回答](https://www.zhihu.com/question/486575193)

<img width="38" height="38" src=":/4bd56607e29c46e587a672e3c15eecca"/>]\(<https://www.zhihu.com/people/chanmufeng>)

[蝉沐风](https://www.zhihu.com/people/chanmufeng)

[​](https://www.zhihu.com/question/48510028)

山东大学 管理学硕士在读

66 人赞同了该回答

面试官如果问你：你会从哪些维度进行MySQL性能优化？你会怎么回答？

所谓的性能优化，一般针对的是MySQL查询的优化。既然是优化查询，我们自然要先知道查询操作要经过哪些环节，然后思考可以在哪些环节进行优化。

我之前写过\*\*[一条SQL查询语句是如何执行的？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI1MDU0MTc2MQ%3D%3D%26mid%3D2247484069%26idx%3D1%26sn%3Dd40d90ab9e3041757262be5192a46e9e%26chksm%3De981e10bdef6681dde2ede9c1293e4b379fb827ab3c7d64ae828311c4ee14e19e20d7537d5f0%23rd)\*\*，感兴趣的朋友可以阅读一下，我用其中的一张图展示查询操作需要经历的基本环节。

<img width="654" height="584" src=":/aa804cc31b884ff4882af7815142a9c7"/>

SQL查询的环节

下面从5个角度介绍一下MySQL优化的一些策略。

<img width="654" height="608" src=":/d9c1b9ca9e104f4db07c28e20c498444"/>

image-20220405204100602

## **1. 连接配置优化**

处理连接是MySQL客户端和MySQL服务端亲热的第一步，第一步都迈不好，也就别谈后来的故事了。

既然连接是双方的事情，我们自然从服务端和客户端两个方面来进行优化喽。

### **1.1 服务端配置**

服务端需要做的就是尽可能地多接受客户端的连接，或许你遇到过`error 1040: Too many connections`的错误？就是服务端的胸怀不够宽广导致的，格局太小！

<img width="654" height="697" src=":/2d7095308c1242b992e1ed7518244cf6"/>

感谢媳妇儿给画的图

我们可以从两个方面解决连接数不够的问题：

1. 增加可用连接数，修改环境变量`max_connections`，默认情况下服务端的最大连接数为`151`个

```
mysql> show variables like 'max_connections';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| max_connections | 151   |
+-----------------+-------+
1 [row in set](https://www.zhihu.com/search?q=row%20in%20set&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D) (0.01 sec)
```

1. 及时释放不活动的连接，系统默认的客户端超时时间是28800秒（8小时），我们可以把这个值调小一点

```
mysql> show variables like 'wait_timeout';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| wait_timeout  | 28800 |
+---------------+-------+
1 row in set (0.01 sec)
```

> MySQL有非常多的配置参数，并且大部分参数都提供了默认值，默认值是MySQL作者经过精心设计的，完全可以满足大部分情况的需求，不建议在不清楚参数含义的情况下贸然修改。

### **1.2 客户端优化**

客户端能做的就是尽量减少和服务端建立连接的次数，已经建立的连接能凑合用就凑合用，别每次执行个SQL语句都创建个新连接，服务端和客户端的资源都吃不消啊。

解决的方案就是使用**连接池**来复用连接。

常见的数据库连接池有`DBCP`、`C3P0`、阿里的`Druid`、`Hikari`，前两者用得很少了，后两者目前如日中天。

但是需要注意的是连接池并不是越大越好，比如`Druid`的默认最大连接池大小是8，`Hikari`默认最大连接池大小是10，盲目地加大连接池的大小，系统执行效率反而有可能降低。为什么？

对于每一个连接，服务端会创建一个单独的线程去处理，连接数越多，服务端创建的线程自然也就越多。而线程数超过CPU个数的情况下，CPU势必要通过分配时间片的方式进行线程的上下文切换，频繁的上下文切换会造成很大的性能开销。

\*\*[Hikari官方](https://link.zhihu.com/?target=https%3A//github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)\*\*给出了一个`PostgreSQL`数据库连接池大小的建议值公式，`CPU核心数*2+1`。假设服务器的CPU核心数是4，把连接池设置成9就可以了。这种公式在一定程度上对其他数据库也是适用的，大家面试的时候可以吹一吹。

## **2. 架构优化**

### **2.1 使用缓存**

系统中难免会出现一些比较慢的查询，这些查询要么是数据量大，要么是查询复杂（关联的表多或者是计算复杂），使得查询会长时间占用连接。

如果这种数据的实效性不是特别强（不是每时每刻都会变化，例如每日报表），我们可以把此类数据放入缓存系统中，在数据的缓存有效期内，直接从缓存系统中获取数据，这样就可以减轻数据库的压力并提升查询效率。

<img width="654" height="208" src=":/fdde66487cc94db7aca3cecfd382e58b"/>

缓存的使用

### **2.2 读写分离（集群、主从复制）**

项目的初期，数据库通常都是运行在一台服务器上的，用户的所有读写请求会直接作用到这台数据库服务器，单台服务器承担的并发量毕竟是有限的。

针对这个问题，我们可以同时使用多台数据库服务器，将其中一台设置为为小组长，称之为`master`节点，其余节点作为组员，叫做`slave`。用户写数据只往`master`节点写，而读的请求分摊到各个`slave`节点上。这个方案叫做**读写分离**。给组长加上组员组成的小团体起个名字，叫**集群**。

<img width="654" height="549" src=":/b2fc7075ce0d410aaa9489e937faab64"/>

这就是集群

> 注：很多开发者不满`master-slave`这种具有侵犯性的词汇（因为他们认为会联想到种族歧视、黑人奴隶等），所以发起了一项更名运动。\
> 受此影响MySQL也会逐渐停用`master`、`slave`等术语，转而用`source`和`replica`替代，大家碰到的时候明白即可。

使用集群必然面临一个问题，就是多个节点之间怎么保持数据的一致性。毕竟写请求只往`master`节点上发送了，只有`master`节点的数据是最新数据，怎么把对`master`节点的写操作也同步到各个`slave`节点上呢？

**主从复制**技术来了！我在\*\*[一条SQL更新语句是如何执行的？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI1MDU0MTc2MQ%3D%3D%26mid%3D2247484093%26idx%3D1%26sn%3Df0fb512d536701c3e0ecdbf330fd6f9d%26chksm%3De981e113def668058493e9102039b45034312946326fca9906744615b4547a364aa7bc445c16%26token%3D795558921%26lang%3Dzh_CN%23rd)\*\*中粗浅地介绍了一下binlog日志，我直接搬过来了。

`binlog`是实现MySQL主从复制功能的核心组件。`master`节点会将所有的写操作记录到binlog中，`slave`节点会有专门的I/O线程读取`master`节点的binlog，将写操作同步到当前所在的`slave`节点。

<img width="654" height="461" src=":/c920babd913b4d1691dae3b68ae3b469"/>

主从复制

这种集群的架构对减轻主数据库服务器的压力有非常好的效果，但是随着业务数据越来越多，如果某张表的数据量急剧增加，单表的查询性能就会大幅下降，而这个问题是读写分离也无法解决的，毕竟所有节点存放的是一模一样的数据啊，单表查询性能差，说的自然也是所有节点性能都差。

这时我们可以把单个节点的数据分散到多个节点上进行存储，这就是**分库分表**。

### **2.3 分库分表**

分库分表中的节点的含义比较宽泛，要是把数据库作为节点，那就是分库；如果把单张表作为节点，那就是分表。

大家都知道分库分表分成垂直分库、垂直分表、水平分库和水平分表，但是每次都记不住这些概念，我就给大家详细说一说，帮助大家理解。

### **2.3.1 垂直分库**

<img width="654" height="338" src=":/5baa8ba205ad41d5a7cbbeb899d13487"/>

垂直分库

在单体数据库的基础上垂直切几刀，按照业务逻辑拆分成不同的数据库，这就是**垂直分库**啦。

<img width="654" height="311" src=":/5e76729c2577458e97969ede1c3c2eac"/>

垂直分库

### **2.3.2 垂直分表**

<img width="654" height="225" src=":/0a045d70179f424998e409192d2c5ed2"/>

垂直分表

垂直分表就是在单表的基础上垂直切一刀（或几刀），将一个表的多个字短拆成若干个小表，这种操作需要根据具体业务来进行判断，通常会把经常使用的字段（热字段）分成一个表，不经常使用或者不立即使用的字段（冷字段）分成一个表，提升查询速度。

<img width="654" height="281" src=":/e33e52be950444938036c35d6bd08cb0"/>

垂直分表

拿上图举例：通常情况下商品的详情信息都比较长，而且查看商品列表时往往不需要立即展示商品详情（一般都是点击详情按钮才会进行显示），而是会将商品更重要的信息（价格等）展示出来，按照这个业务逻辑，我们将原来的商品表做了垂直分表。

### **2.3.3 水平分表**

把单张表的数据按照一定的规则（行话叫分片规则）保存到多个数据表上，横着给数据表来一刀（或几刀），就是**水平分表**了。

<img width="654" height="218" src=":/95a77e4d978840468e69a1c84603f012"/>

水平分表

<img width="654" height="125" src=":/2efdc8ea11814f3fbff2309335f43c68"/>

水平分表

### **2.3.4 水平分库**

**水平分库**就是对单个数据库水平切一刀，往往伴随着水平分表。

<img width="654" height="253" src=":/ff9e826df0d44c97a8499b65e781343e"/>

水平分库

<img width="654" height="474" src=":/60ac86d6f57f4656926c28a55309a561"/>

水平分库

### **2.3.5 总结**

**水平分，主要是为了解决存储的瓶颈；垂直分，主要是为了减轻并发压力。**

### **2.4 消息队列削峰**

通常情况下，用户的请求会[直接访问](https://www.zhihu.com/search?q=%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE\&search_source=Entity\&hybrid_search_source=Entity\&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D)数据库，如果同一时刻在线用户数量非常庞大，极有可能压垮数据库（参考明星出轨或公布恋情时微博的状态）。

这种情况下可以通过使用消息队列降低数据库的压力，不管同时有多少个用户请求，先存入消息队列，然后系统有条不紊地从消息队列中消费请求。

<img width="654" height="641" src=":/48a72fed5c0b4a08be52ac9024aeff0d"/>

队列削峰

## **3. 优化器——SQL分析与优化**

处理完连接、优化完缓存等架构的事情，SQL查询语句来到了解析器和优化器的地盘了。在这一步如果出了任何问题，那就只能是SQL语句的问题了。

只要你的语法不出问题，解析器就不会有问题。此外，为了防止你写的SQL运行效率低，优化器会自动做一些优化，但如果实在是太烂，优化器也救不了你了，只能眼睁睁地看着你的SQL查询沦为**慢查询**。

### **3.1 慢查询**

**慢查询**就是执行地很慢的查询（这句话说得跟废话似的。。。），只有知道MySQL中有哪些慢查询我们才能针对性地进行优化。

因为开启慢查询日志是有性能代价的，因此MySQL默认是关闭慢查询日志功能，使用以下命令查看当前慢查询状态

```
mysql> show variables like 'slow_query%';
+---------------------+--------------------------------------+
| Variable_name       | Value                                |
+---------------------+--------------------------------------+
| slow_query_log      | OFF                                  |
| [slow_query_log](https://www.zhihu.com/search?q=slow_query_log&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D)_file | /var/lib/mysql/9e74f9251f6c-[slow.log](https://www.zhihu.com/search?q=slow.log&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D) |
+---------------------+--------------------------------------+
2 rows in set (0.00 sec)
```

`slow_query_log`表示当前慢查询日志是否开启，`[slow_query_log_file](https://www.zhihu.com/search?q=slow_query_log_file&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D)`表示慢查询日志的保存位置。

除了上面两个变量，我们还需要确定“慢”的指标是什么，即执行超过多长时间才算是慢查询，默认是`10S`，如果改成`0`的话就是记录所有的SQL。

```
mysql> show variables like '%long_query%';
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| long_query_time | 10.000000 |
+-----------------+-----------+
1 row in set (0.00 sec)
```

### **3.1.1 打开慢日志**

有两种打开慢日志的方式

1. 修改配置文件`my.cnf`

此种修改方式系统重启后依然有效

```
# 是否开启慢查询日志
slow_query_log=ON
# 
long_query_time=2
slow_query_log_file=/var/lib/mysql/slow.log
```

1. 动态修改参数（重启后失效）

```
mysql> set @@global.slow_query_log=1;
Query OK, 0 rows affected (0.06 sec)

mysql> set @@global.long_query_time=2;
Query OK, 0 rows affected (0.00 sec)
```

### **3.1.2 慢日志分析**

MySQL不仅为我们保存了慢日志文件，还为我们提供了慢日志查询的工具`mysqldumpslow`，为了演示这个工具，我们先构造一条慢查询：

```
mysql> SELECT sleep(5);
```

然后我们查询用时最多的1条慢查询：

```
[root@iZ2zejfuakcnnq2pgqyzowZ ~]# mysqldumpslow -s t -t 1 -g 'select' /var/lib/mysql/9e74f9251f6c-slow.log

Reading mysql slow query log from /var/lib/mysql/[9e74f9251f6c-slow](https://www.zhihu.com/search?q=9e74f9251f6c-slow&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D).log
Count: 1  Time=10.00s (10s)  Lock=0.00s (0s)  Rows=1.0 (1), root[root]@localhost
  SELECT sleep(N)
```

其中，

- **Count**：表示这个SQL执行的次数
- **Time**：表示执行的时间，括号中的是累积时间
- **Locks**：表示锁定的时间，括号中的是累积时间
- **Rows**：表示返回的记录数，括号中的是累积数

更多关于`mysqldumpslow`的使用方式，可以查阅官方文档，或者执行`[mysqldumpslow](https://www.zhihu.com/search?q=mysqldumpslow&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D) --help`寻求帮助。

### **3.2 查看运行中的线程**

我们可以运行`show full processlist`查看MySQL中运行的所有线程，查看其状态和运行时间，找到不顺眼的，直接kill。

<img width="654" height="137" src=":/8b16eecd2dab46c88e600fbf7cf3d5f0"/>

image-20220405182328247

其中，

- **Id**：线程的唯一标志，可以使用Id杀死指定线程
- **User**：启动这个线程的用户，普通账户只能查看自己的线程
- **Host**：哪个ip和端口发起的连接
- **db**：线程操作的数据库
- **Command**：线程的命令
- **Time**：操作持续时间，单位秒
- **State**：线程的状态
- **Info**：SQL语句的前100个字符

### **3.3 查看服务器运行状态**

使用`SHOW STATUS`查看MySQL服务器的运行状态，有`session`和`global`两种作用域，一般使用`like+通配符`进行过滤。

```
-- 查看select的次数
mysql> SHOW GLOBAL STATUS LIKE 'com_select';
+---------------+--------+
| Variable_name | Value  |
+---------------+--------+
| Com_select    | 168241 |
+---------------+--------+
1 row in set (0.05 sec)
```

### **3.4 查看存储引擎运行信息**

`SHOW ENGINE`用来展示存储引擎的当前运行信息，包括事务持有的表锁、行锁信息；事务的锁等待情况；线程信号量等待；文件IO请求；Buffer pool统计信息等等数据。

例如：

```
SHOW ENGINE INNODB STATUS;
```

上面这条语句可以展示innodb存储引擎的当前运行的各种信息，大家可以据此找到MySQL当前的问题，限于篇幅不在此意义说明其中信息的含义，大家只要知道MySQL提供了这样一个监控工具就行了，等到需要的时候再来用就好。

### **3.5 EXPLAIN执行计划**

通过慢查询日志我们可以知道哪些SQL语句执行慢了，可是为什么慢？慢在哪里呢？

MySQL提供了一个执行计划的查询命令`EXPLAIN`，通过此命令我们可以查看SQL执行的计划，所谓执行计划就是：优化器会不会优化我们自己书写的SQL语句（比如外连接改内连接查询，子查询优化为连接查询...）、优化器针对此条SQL的执行对哪些索引进行了成本估算，并最终决定采用哪个索引（或者最终选择不用索引，而是全表扫描）、优化器对单表执行的策略是什么，等等等等。

> EXPLAIN在MySQL5.6.3之后也可以针对UPDATE、DELETE和INSERT语句进行分析，但是通常情况下我们还是用在SELECT查询上。

这篇文章主要是从宏观上多个角度介绍MySQL的优化策略，因此这里不详细说明`EXPLAIN`的细节，之后单独成篇。

### **3.6 SQL与索引优化**

### **3.6.1 SQL优化**

SQL优化指的是SQL本身语法没有问题，但是有实现相同目的的更好的写法。比如：

- 使用小表驱动大表；用join改写子查询；or改成union
- 连接查询中，尽量减少驱动表的扇出（记录数），访问被驱动表的成本要尽量低，尽量在被驱动表的连接列上建立索引，降低访问成本；被驱动表的连接列最好是该表的主键或者是唯一二级索引列，这样被驱动表的成本会降到更低
- 大偏移量的limit，先过滤再排序

针对最后一条举个简单的例子，下面两条语句能实现同样的目的，但是第二条的执行效率比第一条执行效率要高得多（存储引擎使用的是InnoDB），大家感受一下：

```
-- 1. 大偏移量的查询
mysql> SELECT * FROM user_innodb LIMIT 9000000,10;
Empty set (8.18 sec)

-- 2.先过滤ID（因为ID使用的是索引），再limit
mysql> SELECT * FROM user_innodb WHERE id > 9000000 LIMIT 10;
Empty set (0.02 sec)
```

### **3.6.2 索引优化**

为慢查询创建适当的索引是个非常常见并且非常有效的方法，但是索引是否会被高效使用又是另一门学问了。

我之前写过一篇\*\*[用好MySQL索引，你必须知道的一些事情](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI1MDU0MTc2MQ%3D%3D%26mid%3D2247484338%26idx%3D1%26sn%3Df753421c70f0e436c040af9e969c3331%26chksm%3De981e01cdef6690ae6e4bec7c92b436019f5f30e02f35524ca8e144a92b8aa743fc2c51d2c27%26token%3D1056536482%26lang%3Dzh_CN%23rd)\*\* ，感兴趣的读者可以看一下。

## **4. 存储引擎与表结构**

### **4.1 选择存储引擎**

一般情况下，我们会选择MySQL默认的存储引擎存储引擎`InnoDB`，但是当对数据库性能要求精益求精的时候，存储引擎的选择也成为一个关键的影响因素。

建议根据不同的业务选择不同的存储引擎，例如：

- 查询操作、插入操作多的业务表，推荐使用`MyISAM`；
- 临时表使用`Memory`；
- 并发数量大、更新多的业务选择使用`InnoDB`；
- 不知道选啥直接默认。

### **4.2 优化字段**

字段优化的最终原则是：**使用可以正确存储数据的最小的数据类型**。

### **4.2.1 整数类型**

MySQL提供了6种整数类型，分别是

- **tinyint**
- **smallint**
- **mediumint**
- **int**
- **integer**
- **bigint**

不同的存储类型的最大存储范围不同，占用的存储的空间自然也不同。

例如，是否被删除的标识，建议选用`[tinyint](https://www.zhihu.com/search?q=tinyint&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D)`，而不是`bigint`。

### **4.2.2 字符类型**

你是不是直接把所有字符串的字段都设置为`varchar`格式了？甚至怕不够，还会直接设置成`varchar(1024)`的长度？

如果不确定字段的长度，肯定是要选择`varchar`，但是`varchar`需要额外的空间来记录该字段目前占用的长度；因此如果字段的长度是固定的，尽量选用`char`，这会给你节约不少的内存空间。

### **4.2.3 非空**

非空字段尽量设置成`NOT NULL`，并提供默认值，或者使用特殊值代替`NULL`。

因为`NULL`类型的存储和优化都会存在性能不佳的问题，具体原因在这里就不展开了。

### **4.2.4 不要用外键、触发器和视图功能**

这也是「阿里巴巴开发手册」中提到的原则。原因有三个：

1. 降低了可读性，检查代码的同时还得查看数据库的代码；
2. 把计算的工作交给程序，数据库只做好存储的工作，并把这件事情做好；
3. 数据的完整性校验的工作应该由开发者完成，而不是依赖于外键，一旦用了外键，你会发现测试的时候随便删点垃圾数据都变得异常艰难。

### **4.2.5 图片、音频、视频存储**

不要直接存储大文件，而是要存储大文件的访问地址。

### **4.2.6 大字段拆分和数据冗余**

**大字段拆分**其实就是前面说过的垂直分表，把不常用的字段或者数据量较大的字段拆分出去，避免列数过多和数据量过大，尤其是习惯编写`SELECT *`的情况下，列数多和数据量大导致的问题会被严重放大！

**字段冗余**原则上不符合[数据库设计范式](https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F\&search_source=Entity\&hybrid_search_source=Entity\&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2425182871%7D)，但是却非常有利于快速检索。比如，合同表中存储客户id的同时可以冗余存储客户姓名，这样查询时就不需要再根据客户id获取用户姓名了。因此针对业务逻辑适当做一定程度的冗余也是一种比较好的优化技巧。

## **5. 业务优化**

严格来说，业务方面的优化已经不算是MySQL调优的手段了，但是业务的优化却能非常有效地减轻数据库访问压力，这方面一个典型例子就是淘宝，下面举几个简单例子给大家提供一下思路：

1. 以往都是双11当晚开始买买买的模式，最近几年双11的预售战线越拉越长，提前半个多月就开始了，而且各种定金红包模式丛出不穷，这种方式叫做**预售分流**。这样做可以分流客户的服务请求，不必等到双十一的凌晨一股脑地集体下单；
2. 双十一的凌晨你或许想查询当天之外的订单，但是却查询失败；甚至支付宝里的小鸡的口粮都被延迟发放了，这是一种**降级策略**，集结不重要的服务的计算资源，用来保证当前最核心的业务；
3. 双十一的时候支付宝极力推荐使用花呗支付，而不是银行卡支付，虽然一部分考量是提高软件粘性，但是另一方面，使用余额宝实际使用的阿里内部服务器，访问速度快，而使用银行卡，需要调用银行接口，相比之下操作要慢了许多。

***

MySQL优化的总结写到此就结束了，其中有不少细节没有提及，多少让我感觉这篇文章不完美。但是有些知识点掰开讲又太多了，不可能一下子全部写下，之后再好好写吧。

我是蝉沐风，公众号「蝉沐风」，一个认真写文章的技术人，下期见！

[发布于 2022-04-06 07:54](https://www.zhihu.com/question/486575193/answer/2425182871)

#### 更多回答

<img width="38" height="38" src=":/8e415260379e4697a39b1250a4b7d9b3"/>]\(<https://www.zhihu.com/people/xi-you-37-14-40>)

[托尼学长](https://www.zhihu.com/people/xi-you-37-14-40)

​<img width="15" height="15" src=":/27d6f26bb7d746daa6f837ec2f8d3956"/>

最近面试一些小朋友，简历上赫然写着“擅长MySQL数据库优化”。

然后，我每每好奇地问上两句，你都用了什么方式做的数据库优化啊，基本上千篇一律地回复就是三个字：“加索引。”（手动狗头）

下面跟大家成体系化地详谈一下，MySQL数据库的优化方式有哪些？

既然谈到优化，一定想到要从多个维度进行优化。

**这里的优化维度有四个：硬件配置、参数配置、表结构设计和SQL语句及索引。**

其中 SQL 语句相关的优化手段是最为重要的。

## **硬件配置**

硬件方面的优化可以有 **对磁盘进行扩容、将机械硬盘换为SSD，或是把CPU的核数往上提升一些，增强数据库的计算能力，或是把内存扩容了，让Buffer Pool能吃进更多数据，** 等等。但这个优化手段成本最高，但见效最快。

有句话怎么��的来着，能通过硬件升级来解决的事情，千万别碰代码。哈哈。

## **参数配置**

### **保证从内存读取**

MySQL 会在内存中保存一定的数据，通过 **LRU（最近最少使用）算法**将不常访问的数据保存在硬盘文件中。尽可能的扩大内存中的数据量，将数据保存在内存中，从内存中读取数据，可以提升 MySQL 性能。

MySQL 使用优化过后的 LRU 算法：

> 普通LRU：末尾淘汰法，新数据从链表头部加入，释放空间时从末尾淘汰\
> 改进LRU：链表分为new和old两个部分，加入元素时并不是从表头插入，而是从中间 midpoint位置插入，如果数据很快被访问，那么page就会向new列表头部移动，如果 数据没有被访问，会逐步向old尾部移动，等待淘汰。每当有新的page数据读取到buffer pool时，InnoDb引擎会判断是否有空闲页，是否足够，如果有就将free page从free list列表删除，放入到LRU列表中。没有空闲页，就会根据LRU算法淘汰LRU链表默认的页，将内存空间释放分配给新的页。

LRU 算法针对的是 MySQL 内存中的结构，这里有个区域叫 **Buffer Pool（缓冲池）** 作为数据读写的缓冲区域。把这个区域进行相应的扩大即可提升性能，当然这个参数要针对服务器硬件的实际情况进行调整。

通过以下命令可以查看相应的BufferPool的相关参数：

```
show global status like 'innodb_buffer_pool_pages_%'
```

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='539'%20height='280'></svg>)

输入以下命令可以查看 BufferPool 的大小：

```
show variables like "%innodb_buffer_pool_size%"
```

在这里我们可以修改这个参数的值，如果该服务器是 MySQL 专用的服务器，我们可以 **修改为总内存的 60%\~80%** ，当然不能影响系统程序的运行。

这个参数是只读的，可以在 MySQL 的配置文件（my.cnf 或 my.ini）中进行修改。Linux 的配置文件为 **my.cnf**。

```
# 修改缓冲池大小为750M
innodb_buffer_pool_size = 750M
```

### **数据预热**

数据预热相当于将磁盘中的数据提前放入 BufferPool 内存缓冲池内。一定程度提升了读取速度。

对于 InnoDB，这里提供一份预热 SQL 脚本：

```
#mysql5.7版本中，如果DISTINCT和order by一起使用将会报3065错误，sql语句无法执行。这是由于5.7版本语法比之前版本语法要求更加严格导致的。
#推荐在mysql的配置文件my.cnf文件(linux)/my.ini文件(window) 的mysqld中增加或者修改sql_model配置选项
#sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION
#重启后生效
SELECT DISTINCT
    CONCAT('SELECT ',rowlist,' FROM ',db,'.',tb,
    ' ORDER BY ',rowlist,';') selectSql
    FROM
    (
        SELECT
            engine,table_schema db,table_name tb,
            index_name,GROUP_CONCAT(column_name ORDER BY seq_in_index) rowlist
        FROM
        (
            SELECT
                B.engine,A.table_schema,A.table_name,
                A.index_name,A.column_name,A.seq_in_index
            FROM
                information_schema.statistics A INNER JOIN
                (
                    SELECT engine,table_schema,table_name
                    FROM information_schema.tables WHERE
                    engine='InnoDB'
                ) B USING (table_schema,table_name)
            WHERE B.table_schema NOT IN ('information_schema','mysql')
            ORDER BY table_schema,table_name,index_name,seq_in_index
        ) A
        GROUP BY table_schema,table_name,index_name
    ) AA 
ORDER BY db,tb;
```

### **降低磁盘的写入次数**

（1）增大 redo log，减少落盘次数：

redo log 是重做日志，用于保证数据的一致，减少落盘相当于减少了系统 IO 操作。

innodb\_log\_file\_size 设置为 0.25 \* innodb\_buffer\_pool\_size

（2）通用查询日志、慢查询日志可以不开 ，binlog 可开启。

通用查询和慢查询日志也是要落盘的，可以根据实际情况开启，如果不需要使用的话就可以关掉。binlog 用于恢复和主从复制，这个可以开启。

查看相关参数的命令：

```
# 慢查询日志
show variables like 'slow_query_log%'
# 通用查询日志
show variables like '%general%';
# 错误日志
show variables like '%log_error%'
# 二进制日志
show variables like '%binlog%';
```

（3）写 redo log 策略 innodb\_flush\_log\_at\_trx\_commit 设置为 0 或 2

对于不需要强一致性的业务，可以设置为 0 或 2。

- 0：每隔 1 秒写日志文件和刷盘操作（写日志文件 LogBuffer --> OS cache，刷盘 OS cache --> 磁盘文件），最多丢失 1 秒数据
- 1：事务提交，立刻写日志文件和刷盘，数据不丢失，但是会频繁 IO 操作
- 2：事务提交，立刻写日志文件，每隔 1 秒钟进行刷盘操作

### **系统调优参数**

**back\_log**

back\_log值可以指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySQL的连接数据达到max\_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back\_log，如果等待连接的数量超过back\_log，将不被授予连接资源。可以从默认的50升至500。

**wait\_timeout**

数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时。

**max\_user\_connection**

最大连接数，默认为0无上限，最好设一个合理上限。

**thread\_concurrency**

并发线程数，设为CPU核数的两倍。

**skip\_name\_resolve**

禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问。

**key\_buffer\_size**

索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like 'key\_read%'，保证key\_reads / key\_read\_requests在0.1%以下最好。

**innodb\_buffer\_pool\_size**

缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like 'Innodb\_buffer\_pool\_read%'，保证 (Innodb\_buffer\_pool\_read\_requests – Innodb\_buffer\_pool\_reads) / Innodb\_buffer\_pool\_read\_requests越高越好。

**innodb\_additional\_mem\_pool\_size**

InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小。

**innodb\_log\_buffer\_size**

InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB。

**query\_cache\_size**

缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们数据变化非常频繁的情况下，使用Query Cache可能得不偿失。根据命中率(Qcache\_hits/(Qcache\_hits+Qcache\_inserts)\*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大。可以通过命令show status like 'Qcache\_%'查看目前系统Query catch使用大小。

**read\_buffer\_size**

MySQL读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小来提高其性能。

**sort\_buffer\_size**

MySQL执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort\_buffer\_size变量的大小。

**read\_rnd\_buffer\_size**

MySQL的随机读缓冲区大小。当按任意顺序读取行时(例如按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。

**record\_buffer**

每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值。

**thread\_cache\_size**

保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的。

**table\_cache**

类似于thread\_cache \_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM。

## **表结构设计**

### **设计聚合表**

设计聚合表，一般针对于统计分析功能，或者实时性不高的需求（报表统计，数据分析等系统），这是一种空间 + 时延性换时间的思想。

### **设计冗余字段**

为减少关联查询，创建合理的冗余字段（创建冗余字段还需要注意数据一致性问题），当然，如果冗余字段过多，对系统复杂度和插入性能会有影响。

### **分表**

分表分为垂直拆分和水平拆分两种。

垂直拆分，适用于字段太多的大表，比如：一个表有100多个字段，那么可以把表中经常不被使用的字段或者存储数据比较多的字段拆出来。

水平拆分，比如：一个表有5千万数据，那按照一定策略拆分成十个表，每个表有500万数据。这种方式，除了可以解决查询性能问题，也可以解决数据写操作的热点征用问题。

### **字段的设计**

数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。

- 使用可以存下数据最小的数据类型，合适即可
- 尽量使用TINYINT、SMALLINT、MEDIUM\_INT作为整数类型而非INT，如果非负则加上UNSIGNED；
- VARCHAR的长度只分配真正需要的空间；
- 对于某些文本字段，比如"省份"或者"性别"，使用枚举或整数代替字符串类型；在MySQL中， ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多
- 尽量使用TIMESTAMP而非DATETIME；
- 单表不要有太多字段，建议在20以内；
- 尽可能使用 not null 定义字段，null 占用4字节空间，这样在将来执行查询的时候，数据库不用去比较NULL值。
- 用整型来存IP。
- 尽量少用 text 类型，非用不可时最好考虑拆表。

## **SQL语句及索引**

如果发现SQL查询比较慢，可以开启慢查询日志进行排查。

```
# 开启全局慢查询日志
SET global slow_query_log = ON;
# 设置慢查询日志文件名
SET global slow_query_log_file = 'slow-query.log';
# 记录未使用索引的SQL
SET global log_queries_not_using_indexes = ON;
# 慢查询的时间阈值，默认10秒
SET long_query_time = 10;
```

注：索引并不是越多越好，要根据查询有针对性的创建。

### **索引创建和使用原则**

- 单表查询：哪个列作查询条件，就在该列创建索引
- 多表查询：left join 时，索引添加到右表关联字段；right join 时，索引添加到左表关联字段
- 不要对索引列进行任何操作（计算、函数、类型转换）
- 索引列中不要使用 !=，<> 非等于
- 字符字段只建前缀索引，最好不要做主键；
- 尽量不用UNIQUE，由程序保证约束
- 不用外键，由程序保证约束
- 索引列不要为空，且不要使用 is null 或 is not null 判断
- 索引字段是字符串类型，查询条件的值要加''单引号，避免底层类型自动转换

### **使用 EXPLAIN 分析 SQL**

这里对explain的结果进行简单说明：

- select\_type：查询类型

- SIMPLE 简单查询

- PRIMARY 最外层查询

- UNION union后续查询

- SUBQUERY 子查询

- type：查询数据时采用的方式

- ALL 全表\*\*（性能最差）\*\*

- index 基于索引的全表

- range 范围 （< > in）

- ref 非唯一索引单值查询

- const 使用主键或者唯一索引等值查询

- possible\_keys：可能用到的索引

- key：真正用到的索引

- rows：预估扫描多少行记录

- key\_len：使用了索引的字节数

- Extra：额外信息

- Using where 索引回表

- Using index 索引直接满足条件

- Using filesort 需要排序

- Using temprorary 使用到临时表

对于以上的几个列，我们重点关注的是type，最直观的反映出SQL的性能。

### **SQL语句尽可能简单**

一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库。

### **对于连续数值，使用 BETWEEN 不用 IN**

SELECT id FROM t WHERE num BETWEEN 1 AND 5；

### **SQL 语句中 IN 包含的值不应过多**

MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。如果数值较多，需要在内存进行排序操作，产生的消耗也是比较大的。

### **SELECT 语句必须指明字段名称**

SELECT \* 增加很多不必要的消耗（CPU、IO、内存、网络带宽）；减少了使用覆盖索引的可能性。

### **当只需要一条数据的时候，使用 limit 1**

limit 相当于截断查询。

例如：对于select \* from user limit 1; 虽然进行了全表扫描，但是limit截断了全表扫描，从0开始取了1条数据。

### **排序字段加索引**

排序的字段建立索引在排序的时候也会用到

### **如果限制条件中其他字段没有索引，尽量少用or**

### **尽量用 union all 代替 union**

union和union all的差别就在于union会对数据做一个distinct的动作，而这个distanct动作的速度则取决于现有数据的数量，数量越大则时间也越慢。而对于几个数据集，要确保数据集之间的数据互相不重复，基本是O(n)的算法复杂度。

### **区分 in 和 exists、not in 和 not exists**

如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。

### **使用合理的分页方式以提高分页的效率**

limit m n，其中的m偏移量尽量小。m越大查询越慢。

### **避免使用 % 前缀模糊查询**

例如：like '%name'或者like '%name%'，这种查询会导致索引失效而进行全表扫描。但是可以使用like 'name%'，这种会使用到索引。

### **避免在 where 子句中对字段进行表达式操作**

这种不会使用到索引：

```
select user_id,user_project from user_base where age*2=36;
```

可以改为：

```
select user_id,user_project from user_base where age=36/2;
```

任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。

### **避免隐式类型转换**

where 子句中出现的 column 字段要和数据库中的字段类型对应

### **必要时可以使用 force index 来强制查询走某个索引**

有的时候 MySQL 优化器采取它认为合适的索引来检索 SQL 语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用 forceindex 来强制优化器使用我们制定的索引。

### **使用联合索引时注意范围查询**

对于联合索引来说，如果存在范围查询，比如between、>、<等条件时，会造成后面的索引字段失效。

### **某些情况下，可以使用连接代替子查询**

因为使用 join，MySQL 不会在内存中创建临时表。

### **使用JOIN的优化**

使用小表驱动大表，例如使用inner join时，优化器会选择小表作为驱动表

### **小表驱动大表，即小的数据集驱动大的数据集**

如：以 A，B 两表为例，两表通过 id 字段进行关联。

```
#当 B 表的数据集小于 A 表时，用 in 优化 exist；使用 in ，两表执行顺序是先查 B 表，再查 A 表
select * from A where id in (select id from B)

#当 A 表的数据集小于 B 表时，用 exist 优化 in；使用 exists，两表执行顺序是先查 A 表，再查 B 表
select * from A where exists (select 1 from B where B.id = A.id)
```

上面都是一些常规的优化方法，我们还可以使用：主从和分库。

### 主从

主从相对比较简单，从运维层面搭建好从库后，工程师要做的就是制定路由策略。

路由策略有如下两种：

读写分离模式，所有写操作和对实时性要求较高的by id查询走主库，剩下的都走从库，从库采用Round Robin模式。

链路隔离模式：写操作和核心操作对应的SQL走主库，耗时大、非核心操作的SQL走从库。

### 分库

分库策略需要根据业务场景制定，最常见的有两种：按照年月分库和按照角色分库。

按照角色分库，最经典的就是淘宝基于订单的买家库和卖家库。

### 结语

整体来讲，这篇数据库优化应该总结得还算全面吧，如果有新的方案策略，我再往上添加。

**最后，再给知友们来一波福利**。

本人在去年看机会的时候，也从网上找遍了各式各类的八股文资料，但总觉得答案还不够准确，深度还有所欠缺，或是内容组织的逻辑性还不够清晰。

于是，我便自己动手，丰衣足食地自己总结了一套博采众家之长的八股文，那可真是字字斟酌，题题验证。

最终，本人凭借着这套八股文，拿到了字节跳动3-1和百度T7的offer。

现在，我“大公无私”地把它分享出来，希望更多的同学可以由此受益。

[](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkxMDUxNzM2Nw%3D%3D%26mid%3D2247483670%26idx%3D1%26sn%3Df60150f5cadf55e72a80924de12feeba%26chksm%3Dc12b740ef65cfd1828f3751785ef43078d9334ece9ac0884949650a7646239b08f30379455f1%26token%3D1995142886%26lang%3Dzh_CN%23rd)

最后，祝大家工作顺利，纵情向前，人人都能收获自己满意的offer。

<img width="38" height="38" src=":/94fc3ce0b6ee487f87ab41f01a9d272f"/>]\(<https://www.zhihu.com/people/Java_3y>)

[Java3y](https://www.zhihu.com/people/Java_3y)

**面试官**：**要不你来讲讲你们对MySQL是怎么调优的？**

**候选者**：哇，这命题很大阿…我认为，对于开发者而言，对MySQL的调优重点一般是在「开发规范」、「数据库索引」又或者说解决线上慢查询上。

**候选者**：而对于MySQL内部的参数调优，由专业的DBA来搞。

**面试官**：扯了这么多，你就是想表达你不会MySQL参数调优，对吧

**候选者**：草，被发现了。

**面试官**：**那你来聊聊你们平时开发的规范和索引这块，平时是怎么样的吧。**

**候选者**：嗯，首先，我们在生产环境下，创建数据库表，都是在工单系统下完成的（那就自然需要DBA审批）。如果在创建表时检测到没有创建索引，那就会直接提示warning（：

<img width="654" height="148" src=":/c96445cdbebe4531b1fcf74cae86b832"/>

**候选者**：理论上来说，如果表有一定的数据量，那就应该要创建对应的索引。从数据库查询数据需要注意的地方还是蛮多的，其中很多都是平时积累来的。比如说：

**候选者**：1. 是否能使用「覆盖索引」，减少「回表」所消耗的时间。意味着，我们在select 的时候，一定要指明对应的列，而不是select \*

**候选者**：2. 考虑是否组建「联合索引」，如果组建「联合索引」，尽量将区分度最高的放在最左边，并且需要考虑「最左匹配原则」

**候选者**：3.对索引进行函数操作或者表达式计算会导致索引失效

**候选者**：4.利用子查询优化超多分页场景。比如 limit offset , n 在MySQL是获取 offset + n的记录，再返回n条。而利用子查询则是查出n条，通过ID检索对应的记录出来，提高查询效率。

**面试官**：嗯…

**候选者**：5.通过explain命令来查看SQL的执行计划，看看自己写的SQL是否走了索引，走了什么索引。通过show profile 来查看SQL对系统资源的损耗情况（不过一般还是比较少用到的）

**候选者**：6.在开启事务后，在事务内尽可能只操作数据库，并有意识地减少锁的持有时间（比如在事务内需要插入&&修改数据，那可以先插入后修改。因为修改是更新操作，会加行锁。如果先更新，那并发下可能会导致多个事务的请求等待行锁释放）

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1732'%20height='424'></svg>)

**面试官**：嗯，你提到了事务，之前也讲过了事务的隔离级别嘛，**那你线上用的是什么隔离级别？**

**候选者**：嗯，我们这边用的是Read Commit（读已提交），MySQL默认用的是Repeatable read（可重复读）。选用什么隔离级别，主要看应用场景嘛，因为隔离级别越低，事务并发性能越高。

**候选者**：（一般互联网公司都选择Read Commit作为主要的隔离级别）

**候选者**：像Repeatable read（可重复读）隔离级别，就有可能因为「间隙锁」导致的死锁问题。

**候选者**：但可能你已经知道，MySQL默认的隔离级别为Repeatable read。很大一部分原因是在最开始的时候，MySQL的binlog没有row模式，在read commit隔离级别下会存在「主从数据不一致」的问题

**候选者**：binlog记录了数据库表结构和表数据「变更」，比如update/delete/insert/truncate/create。在MySQL中，主从同步实际上就是应用了binlog来实现的（：

**候选者**：有了该历史原因，所以MySQL就将默认的隔离级别设置为Repeatable read

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1358'%20height='218'></svg>)

**面试官**：嗯，那我顺便想问下，你们遇到过类似的问题吗：**即便走对了索引，线上查询还是慢。**

**候选者**：嗯嗯，当然遇到过了

**面试官**：**那你们是怎么做的？**

**候选者**：如果走对了索引，但查询还是慢，那一般来说就是表的数据量实在是太大了。

**候选者**：首先，考虑能不能把「旧的数据」给”删掉”，对于我们公司而言，我们都会把数据同步到Hive，说明已经离线存储了一份了。

**候选者**：那如果「旧的数据」已经没有查询的业务了，那最简单的办法肯定是”删掉”部分数据咯。数据量降低了，那自然，检索速度就快了…

**面试官**：嗯，但一般不会删的

**候选者**：没错，只有极少部分业务可以删掉数据（：

**候选者**：随后，就考虑另一种情况，能不能在查询之前，直接走一层缓存（Redis）。

**候选者**：而走缓存的话，又要看业务能不能忍受读取的「非真正实时」的数据（毕竟Redis和MySQL的数据一致性需要保证），如果查询条件相对复杂且多变的话（涉及各种group by 和sum），那走缓存也不是一种好的办法，维护起来就不方便了…

**候选者**：再看看是不是有「字符串」检索的场景导致查询低效，如果是的话，可以考虑把表的数据导入至Elasticsearch类的搜索引擎，后续的线上查询就直接走Elasticsearch了。

**候选者**：MySQL->Elasticsearch需要有对应的同步程序(一般就是监听MySQL的binlog，解析binlog后导入到Elasticsearch)

**候选者**：如果还不是的话，那考虑要不要根据查询条件的维度，做相对应的聚合表，线上的请求就查询聚合表的数据，不走原表。

**候选者**：比如，用户下单后，有一份订单明细，而订单明细表的量级太大。但在产品侧(前台)透出的查询功能是以「天」维度来展示的，那就可以将每个用户的每天数据聚合起来，在聚合表就是一个用户一天只有一条汇总后的数据。

**候选者**：查询走聚合后的表，那速度肯定杠杠的（聚合后的表数据量肯定比原始表要少很多）

**候选者**：思路大致的就是「以空间换时间」，相同的数据换别的地方也存储一份，提高查询效率

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='2374'%20height='388'></svg>)

**面试官**：**那我还想问下，除了读之外，写性能同样有瓶颈，怎么办？**

**候选者**：你说到这个，我就不困了。

**候选者**：如果在MySQL读写都有瓶颈，那首先看下目前MySQL的架构是怎么样的。

**候选者**：如果是单库的，那是不是可以考虑升级至主从架构，实现读写分离。

**候选者**：简单理解就是：主库接收写请求，从库接收读请求。从库的数据由主库发送的binlog进而更新，实现主从数据一致（在一般场景下，主从的数据是通过异步来保证最终一致性的）

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='622'%20height='250'></svg>)

**面试官**：嗯…

**候选者**：如果在主从架构下，读写仍存在瓶颈，那就要考虑是否要分库分表了

**候选者**：至少在我前公司的架构下，业务是区分的。流量有流量数据库，广告有广告的数据库，商品有商品的数据库。所以，我这里讲的分库分表的含义是：在原来的某个库的某个表进而拆分。

**候选者**：比如，现在我有一张业务订单表，这张订单表在广告库中，假定这张业务订单表已经有1亿数据量了，现在我要分库分表

**候选者**：那就会将这张表的数据分至多个广告库以及多张表中（：

**候选者**：分库分表的最明显的好处就是把请求进行均摊（本来单个库单个表有一亿的数据，那假设我分开8个库，那每个库1200+W的数据量，每个库下分8张表，那每张表就150W的数据量）。

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='784'%20height='248'></svg>)

**面试官**：**你们是以什么来作为分库键的？**

**候选者**：按照我们这边的经验，一般来说是按照userId的（因为按照用户的维度查询比较多），如果要按照其他的维度进行查询，那还是参照上面的的思路（以空间换时间）。

**面试官**：**那分库分表后的ID是怎么生成的？**

**候选者**：这就涉及到分布式ID生成的方式了，思路有很多。有借助MySQL自增的，有借助Redis自增的，有基于「雪花算法」自增的。具体使用哪种方式，那就看公司的技术栈了，一般使用Redis和基于「雪花算法」实现用得比较多。

**候选者**：至于为什么强调自增（还是跟索引是有序有关，前面已经讲过了，你应该还记得）

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1068'%20height='346'></svg>)

**面试官**：嗯，那如果我要分库分表了，迁移的过程是怎么样的呢

**候选者**：我们一般采取「双写」的方式来进行迁移，大致步骤就是：

**候选者**：一、增量的消息各自往新表和旧表写一份

**候选者**：二、将旧表的数据迁移至新库

**候选者**：三、迟早新表的数据都会追得上旧表（在某个节点上数据是同步的）

**候选者**：四、校验新表和老表的数据是否正常（主要看能不能对得上）

**候选者**：五、开启双读（一部分流量走新表，一部分流量走老表），相当于灰度上线的过程

**候选者**：六、读流量全部切新表，停止老表的写入

**候选者**：七、提前准备回滚机制，临时切换失败能恢复正常业务以及有修数据的相关程序。

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1462'%20height='342'></svg>)

**面试官**：嗯…今天就到这吧

**本文总结：**

- 数据库表存在一定数据量，就需要有对应的索引
- 发现慢查询时，检查是否走对索引，是否能用更好的索引进行优化查询速度，查看使用索引的姿势有没有问题
- 当索引解决不了慢查询时，一般由于业务表的数据量太大导致，利用空间换时间的思想
- 当读写性能均遇到瓶颈时，先考虑能否升级数据库架构即可解决问题，若不能则需要考虑分库分表
- 分库分表虽然能解决掉读写瓶颈，但同时会带来各种问题，需要提前调研解决方案和踩坑

**线上不是给你炫技的地方，安稳才是硬道理。能用简单的方式去解决，不要用复杂的方式**

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1440'%20height='810'></svg>)

我最近一直在连载《对线面试官》系列，目前已经连载**38**篇啦！一个**说人话**的面试系列！

[](https://link.zhihu.com/?target=http%3A//javainterview.gitee.io/luffy)

- **[【对线面试官】HTTP](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247485055%26idx%3D1%26sn%3D4aab3ca14e013c031fb0a9617d5049a7%26chksm%3Dfdf0ee20ca8767360e9f07b8fd70a2d83d0745575012629b5b4d6e4ca8efb69232c1a6f1d679%26token%3D711031528%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Java注解](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483821%26idx%3D1%26sn%3De9003410a8d3c8a092de0c4d2002bedd%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Java泛型](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483823%26idx%3D1%26sn%3Dcc887dc2c7e68a69e8d4d141c2ca9b5e%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】 Java NIO](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483854%26idx%3D1%26sn%3Daa450a03ac0d6e8cf12cf13d4719ede3%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Java反射 && 动态代理](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483893%26idx%3D1%26sn%3Daf51e626f2c2baec8cae4f4a15425957%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】多线程基础](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483918%26idx%3D1%26sn%3Dab8550bb284edcf7cf0c6d0b41e0c2f6%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】 CAS](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483977%26idx%3D1%26sn%3D1a3aa3aec27073aa3b422bc41d7fbe2d%26chksm%3Dfdf0ea16ca8763005aff64834eeb7bef08bf4ee2d8febb7e8d4d8e5d1542336e13fac71e2881%26scene%3D21%26cur_album_id%3D1657204970858872832%23wechat_redirect)**
- **[【对线面试官】synchronized](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247483980%26idx%3D1%26sn%3Dc9b620834adb889ad8ccedb6afdcaed1%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】AQS&\&ReentrantLock](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484035%26idx%3D1%26sn%3Dccaec352e192f1fd40020d9a984e9461%26chksm%3Dfdf0eadcca8763ca5c44bd19118fd00e843c163deb40cda444b3fc08430c57760db15eca1ea6%26scene%3D21%26cur_album_id%3D1657204970858872832%23wechat_redirect)**
- **[【对线面试官】线程池](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484036%26idx%3D1%26sn%3D75e9e93a82a811e9c71b8127cf7ac677%26chksm%3Dfdf0eadbca8763cd7ab74757f9472d061c0244d2373a1ea85b1cbc833941441fdb1e91ead5b4%26scene%3D21%26cur_album_id%3D1657204970858872832%23wechat_redirect)**
- **[【对线面试官】ThreadLocal](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484118%26idx%3D1%26sn%3D9526a1dc0d42926dd9bcccfc55e6abc2%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】CountDownLatch和CyclicBarrier](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484363%26idx%3D1%26sn%3D743dcdfb84f83cfc38882407f87c7c6d%26chksm%3Dfdf0eb94ca87628296d86d16769f25e10acd052bcd78f4a4608f4218e4948aff610b04a41f60%26token%3D960279204%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】为什么需要Java内存模型？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484535%26idx%3D1%26sn%3Daf9676b6defcfd862db297b1ee3f4aea%26chksm%3Dfdf0ec28ca87653e84aedd1b5db916d776c46c158afb727467d42a941af85d948046da24b5e5%26token%3D1812893887%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】深入浅出 Java 内存模型](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484606%26idx%3D1%26sn%3D42212c0ac1c123ebee1903d07f88b6db%26chksm%3Dfdf0ece1ca8765f7e623d2a3d19ff637d8f2449db0dea2bb63d87e11f63b482cf16c0a007faf%26token%3D2087444891%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Java从编译到执行，发生了什么？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484557%26idx%3D1%26sn%3D6fb103a2a322effc564fbb04c3b93a6c%26chksm%3Dfdf0ecd2ca8765c4eacc22e54b4bc57888555efee99f1c7e57ee611e07d220b35b2aa658a4ca%26token%3D830702193%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】双亲委派机制](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484581%26idx%3D1%26sn%3D887268251772f4f8fc737d7e4354b5b8%26chksm%3Dfdf0ecfaca8765ec656ca3ea2ae57b33226eef3cbcc2c107168619aa6be37db5b3416ead43b5%26token%3D1009822517%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】JVM内存结构](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484635%26idx%3D1%26sn%3D4ca6f32917ee42a5b5e0443d2262c2ec%26chksm%3Dfdf0ec84ca876592e1c58dbd4d7535f9bb11df1cba5c4e7cd045b87e790cb2ec7ea35302bbd1%26token%3D399434818%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】垃圾回收机制](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484705%26idx%3D1%26sn%3D9955b0cec5acb6b5dc977b949aea9e63%26chksm%3Dfdf0ed7eca876468aed985743371b6fc647b26c7e9c66fd0612b34991c01b28f16b273721201%26token%3D334164983%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】CMS垃圾回收器](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484764%26idx%3D1%26sn%3D67b0e576a4e7660bec0d3e9ac947954d%26chksm%3Dfdf0ed03ca876415f3f0c05f8670497f39a934742012204f18d4c0a79d3d492a1be53859f442%26token%3D1837416809%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】G1垃圾收集器](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484826%26idx%3D1%26sn%3Ded423fab3a263dc05ff022977ea94536%26chksm%3Dfdf0edc5ca8764d3649fce9dfc745bb488ae16b3ddd8268e2305ce3602b54f022d8ed0cf25d6%26token%3D1672285925%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】JVM调优](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247485031%26idx%3D1%26sn%3Dd1a456a1dde946eb8001a5f0b04f6533%26chksm%3Dfdf0ee38ca87672e3ddffe98fbdae813e31dd63419c25bd7387282fe4665af4f6d5826c46b9b%26token%3D711031528%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】List](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484253%26idx%3D1%26sn%3D532db3941f47502582295cbb003f753d%26chksm%3Dfdf0eb02ca8762145c66b33bbb429399f1f0f27b31c22f7cf6c693c235e9a7cffdafb6ce2fdc%26token%3D57394744%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Map](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484280%26idx%3D1%26sn%3D87cfede653dabc26c909823a1dafd615%26chksm%3Dfdf0eb27ca876231095ff99f0b3e30acd7b2ee4cdc7ddb16da0bb6a3b02f531e27324059cf58%26token%3D100834666%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】SpringMVC](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484064%26idx%3D1%26sn%3D3a59514a8262ab61036fc89cf0b0a27e%26chksm%3Dfdf0eaffca8763e90002ce1daf365f717a4bda3e50878f65943f52d14bee78fc65e837ef32f9%26token%3D664255414%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Spring基础](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484147%26idx%3D1%26sn%3Def282cd54351436fc33c47534b4c2ac1%26chksm%3Dfdf0eaacca8763ba9b6c69acdba6b0ae8801405c98295842a0b5d891fe80246d76a2a0470bea%26token%3D1998524575%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】SpringBean生命周期](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484187%26idx%3D1%26sn%3D8f831c40dca9b2a57fdfbd051e4eab44%26chksm%3Dfdf0eb44ca87625253ea831471110860d3f27e04488b2748ba90ad442b079aca3d6b95d31bbe%26token%3D1998524575%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Redis基础](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484227%26idx%3D1%26sn%3D4a124a2dd5ef6ce062abdadf247b5cff%26chksm%3Dfdf0eb1cca87620a8679473dfdd50421eb6ccba2459a7cb59ae1652138f7bb508558f3d4649e%26token%3D57394744%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Redis持久化](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484323%26idx%3D1%26sn%3Dc3306b3f9abb6f880e2672f169202a42%26chksm%3Dfdf0ebfcca8762eaf9b4873e79cd3445857b1f4476a854acdf9c19fb81e1a02146c65cff5078%26token%3D610975656%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Redis主从架构](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484884%26idx%3D1%26sn%3Db944c10afced15b47098853b0ee5456b%26chksm%3Dfdf0ed8bca87649d691703ed5935e8302769c794a1c30b492c10ad890ff92d90969cd5b71fb2%26token%3D869444578%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Redis分片集群](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484915%26idx%3D1%26sn%3Dc50e991f750615c09bb67b2acfa05458%26chksm%3Dfdf0edacca8764ba5487496933956ed53937de742d74e6530e93b370b0f7461959162dd9a402%26token%3D869444578%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】Kafka基础](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484387%26idx%3D1%26sn%3D5bb2ba58776e65f53b091a4bcdb73755%26chksm%3Dfdf0ebbcca8762aadc359066ecd70274fa23ee846f9ba9114017402dcbed415f25f97d3020a6%26token%3D1131755397%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】使用Kafka会考虑什么问题？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484411%26idx%3D1%26sn%3D9c4aaeb44f4d9e09cc796805ada29921%26chksm%3Dfdf0eba4ca8762b234c3f101bb88c5d134554a831cbf4e80b08dc0bfa829e363a4e1e49a8b50%26token%3D649285067%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】MySQL索引](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484431%26idx%3D1%26sn%3D17b9e88233282469481e214a0cd2dc56%26chksm%3Dfdf0ec50ca8765460a20af19101855c859a6350a8dfd6680e7f47c2e73f03de48288184a1bf3%26token%3D310857929%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】MySQL 事务&&锁机制&\&MVCC](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484480%26idx%3D1%26sn%3D3571b89575e8c37c114c9f290b953a1c%26chksm%3Dfdf0ec1fca87650913e6673a453d0ba1614341433aa67dd9977fef7231a3d825f7da4e4a132a%26token%3D1651214636%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】MySQL调优](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484508%26idx%3D1%26sn%3D4e81d365409bf32c08e4ea985e3ca593%26chksm%3Dfdf0ec03ca876515d59c49f033cf83f72b62fafe356e678b4d162ad3623d31bf60fb6620176f%26token%3D336229290%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】如何实现幂等和去重？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484848%26idx%3D1%26sn%3D936898b5e5a2cb1a82b4b017a7c811d5%26chksm%3Dfdf0edefca8764f9b14525354cb701354a59d62619ed7e7c99050e9a53f153d1cb320998a24b%26token%3D1672285925%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】系统需求多变时，如何设计](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484954%26idx%3D1%26sn%3Dd084fdd34d70ece3c3e50931e7394e32%26chksm%3Dfdf0ee45ca876753f59e56f3688d92aecc84eb130f66521642c061a0f52153f0aeb4cbd774ff%26token%3D1443639712%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- **[【对线面试官】设计模式](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NzA3MTc5Mg%3D%3D%26mid%3D2247484979%26idx%3D1%26sn%3Df7ccdc3874e5f966f4bf1db0117115f9%26chksm%3Dfdf0ee6cca87677a95c157c62111303ade115de06890cd1018db169e38d78024c8349658ad21%26token%3D1443639712%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect)**
- ...

【大厂面试知识点】、【简历模板】、【原创文章】电子书，共有1263页

我把这些**上传到网盘**，你们有需要直接下载就好了。做到这份上了，**不会还想白嫖吧**？**点赞**和**转发**又不用钱。

![](data:image/svg+xml;utf8,<svg%20xmlns='http://www.w3.org/2000/svg'%20width='1508'%20height='498'></svg>)

链接:[pan.baidu.com/s/1pQTuKBYs…](https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1pQTuKBYsHLsUR5ORRAnwFg) 密码:3wom

## 收藏等于白嫖，点赞才是真情！

[查看全部 42 个回答](https://www.zhihu.com/question/486575193)

<img width="296" height="247" src=":/98e65999212d45278b12791d6b690bad"/>]\(<https://www.zhihu.com/xen/market/ecom-page/1724029932844355584>)

关于作者

<img width="60" height="60" src=":/f76febe8cbe14a12bd546225e58a3abd"/>]\(<https://www.zhihu.com/people/chanmufeng>)

[蝉沐风](https://www.zhihu.com/people/chanmufeng)

公众号「蝉沐风的码场」主理人

[​](https://zhuanlan.zhihu.com/p/96956163)

山东大学 管理学硕士在读

[回答<br>**37**](https://www.zhihu.com/people/chanmufeng/answers)[文章<br>**28**](https://www.zhihu.com/people/chanmufeng/posts)[关注者<br>**564**](https://www.zhihu.com/people/chanmufeng/followers)

被收藏 次

[计算物理学](https://www.zhihu.com/collection/475948347 "计算物理学")

[j99999999955555](https://www.zhihu.com/people/j99999999955555) 创建

1 人关注

[编程](https://www.zhihu.com/collection/798959066 "编程")

[飞白](https://www.zhihu.com/people/tiansir-wg) 创建

0 人关注

[计算机](https://www.zhihu.com/collection/253617898 "计算机")

[不苦咖啡](https://www.zhihu.com/people/bu-ku-ka-pei-14) 创建

0 人关注

相关问题

[mysql 优化有哪些方法呢？](https://www.zhihu.com/question/483549197) 2 个回答

[mysql 优化有哪几种方法？](https://www.zhihu.com/question/483900728) 0 个回答

[mysql 优化常用有哪几种方法呢？](https://www.zhihu.com/question/483673286) 0 个回答

[mysql 单机优化的方法技巧有哪些？](https://www.zhihu.com/question/590471928) 0 个回答

[mysql 最好的优化方法是什么？为什么？](https://www.zhihu.com/question/575773569) 0 个回答

[广告<br>![广告](https://pic4.zhimg.com/v2-773408974f824aba3cb17224e2ff0128_720w.webp?source=d6434cab)](https://www.zhihu.com/xen/market/ecom-page/1722313440247418880)

 

帮助中心

[知乎隐私保护指引](https://www.zhihu.com/term/privacy)[联系我们](https://www.zhihu.com/contact)

 

举报中心

[涉未成年举报](https://www.zhihu.com/term/child-jubao)[网络谣言举报](https://www.zhihu.com/term/net-report)[涉企虚假举报](https://www.zhihu.com/term/enterprise-fake-info)

 

关于知乎

[下载知乎](https://www.zhihu.com/app/)[知乎招聘](https://app.mokahr.com/apply/zhihu/78336#/)[知乎指南](https://www.zhihu.com/question/19581624)[知乎协议](https://www.zhihu.com/term/zhihu-terms)

[京 ICP 证 110745 号](https://tsm.miit.gov.cn/dxxzsp/) · [京 ICP 备 13052560 号 - 1](https://beian.miit.gov.cn/) · [京公网安备 11010802020088 号](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010802020088) · [京网文\[2022\]2674-081 号](https://www.zhihu.com/certificates) · [药品医疗器械网络信息服务备案（京）网药械信息备字（2022）第00334号](https://pic3.zhimg.com/v2-c280f8bce57f9b045b83185384d86027.png) · [广播电视节目制作经营许可证:（京）字第06591号](https://www.zhihu.com/certificates) · 服务热线：400-919-0001 · [Investor Relations](https://ir.zhihu.com) · © 2024 知乎 北京智者天下科技有限公司版权所有 · 违法和不良信息举报：010-82716601 · [举报邮箱：jubao@zhihu.com](mailto:jubao@zhihu.com)

<img width="80" height="38" src=":/938f3a1b547540d98e7ed639638ff111"/>
